---
title: "Data cleaning for analysis for COMPS"
author: "Michelle.VanTieghem"
date: "Dec 1, 2019"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: yes
---

```{r, warning = F, message = F}
library(tidyverse)
```


# Set up data
## load behavior master, which includes demographic variables 
generated: 3_progress_report_Scans_and_behavior.Rmd 
has all behavior data, QC info, and demographics. long format, by run.
```{r}
load("../../behavioral_data/3_Effort_task_data/compiled/compiled_effort_scan_version_filtered_usable_with_demo.Rdata")
nrow(df_by_run_usable_beh)

```

## subset for comparisons only
note: this data is by RUN 
```{r}
beh_comp_by_run <- df_by_run_usable_beh %>%
  filter(PI_DA == 0) %>%
  rename(proportion_hard = N_prop_hard) %>%
  mutate(Run_Number.n = ifelse(Run_number == "RUN1", 1, 2), 
         # answers of 4 for perceived control are not plausible, error data!! 
         perceived_control = ifelse(perceived_control == 4, NA, perceived_control))
nrow(beh_comp_by_run)

```


## load in long-formatted behavioral data per subject 
generated in behavior_perproc_scripts/1_effort_task_behavior_preproc.Rmd
add a couple more variables 
```{r}
load("../../behavioral_data/3_effort_task_data/compiled/compiled_long_format_all_data.Rdata")

behavior_long_data <- behavior_long_data %>%
  rename(SUBJECTID = SUB) %>%
  # add turtle feedback! if they didn't make it to top of green bar.
  mutate(Feedback = as.factor(ifelse(Accuracy == 0, "Too_slow",
                                    ifelse(Accuracy == 1 & Reward_received == 1, "Reward", 
                                           ifelse(Accuracy == 1 & Reward_received == 0, "Setback", 
                                                  ifelse(is.na(Reward_received), NA, "fix")))))) %>% 
  rename(computer = task_version)
# NA = missed choice, so no feedback phase.s
summary(behavior_long_data$Feedback)


# get the max that their hard task was titrated to.
by_subj <- behavior_long_data %>%
  group_by(SUBJECTID) %>%
  dplyr::summarize(hard_task_titration = max(max_keys, na.rm = T)) 
#head(by_subj)
# everyone is a 3!!! so no point in caring about easy task.
#summary(by_subj$hard_task_titration[by_subj$Effort_Choice == "Easy"])
# add this subject-level covariate into the long df.
behavior_long_data <- merge(behavior_long_data, by_subj, by = "SUBJECTID")

```

### merge into a long dataframe (by trial) 
beh_comp_by_run is already filtered for usable, long data is not. do not say "all = T"
```{r}
beh_comp_long <- merge(beh_comp_by_run, behavior_long_data, by = c("SUBJECTID", "Run_number"))
nrow(beh_comp_long)


# any dupliocated trials? 
trial_check <- beh_comp_long %>%
  group_by(SUBJECTID, Run_number) %>%
  summarize(N_trials = n()) %>% 
  filter(N_trials > 22)
trial_check # none!

# any duplicated runs?
run_check <- beh_comp_by_run %>%
  group_by(SUBJECTID) %>%
  summarize(N_runs = n()) %>%
  filter(N_runs > 2)
run_check # none! 

```


## Set up long data for behavior analysis 

### clean data 
double check that we excluded subjects with extreme reinforcement rates, too many "too slow" resps, or not enough choices.

```{r}

# re-ordering the entire dataframe by Trial Number and run number! 
beh_comp_long <- beh_comp_long[order(beh_comp_long$SUBJECTID, beh_comp_long$Run_Number.n, beh_comp_long$Trial_Number),]

beh_comp_long2 <- beh_comp_long %>%
   filter(#not doing this yet- secondary analysis exclusion 
     #Reinforce_rate > .3 & Reinforce_rate < .7 & 
          # exclude people with too many missing
          Prop_tooslow < .5 & N_choices_resp > 15 & 
            # missed trials
            Effort_Choice != "Miss") %>%
          mutate( Effort_Choice.n = ifelse(Effort_Choice == "Easy", 0, 1))

# how many subjects excluded? NONE - because we did our code correctly in behavioral preprocessing.
length(unique(beh_comp_long2$SUBJECTID)) - length(unique(beh_comp_long$SUBJECTID))

```

### clean data more 
run number and trial number variables 
add extra covariates 
```{r}
beh_comp_long3 <- beh_comp_long2 %>%
  mutate(Trial_Number = as.numeric(as.character(Trial_Number)),
         # convert post-test from character to numeric
         # these are all subject-level covariaces
         hard_effort_perceived = as.numeric(hard_effort), 
         easy_effort_perceived = as.numeric(easy_effort), 
         fun = as.numeric(fun),
         motivated = as.numeric(motivated),
         sleepy = as.numeric(sleepy),
         frustrated = as.numeric(frustrated),
         win_feeling = as.numeric(win_feeling),
         lose_feeling = as.numeric(lose_feeling),
         perceived_reinforce = as.numeric(perceived_reinforce),
         perceived_control = as.numeric(perceived_control),
         # calculate these trial-by-trial covariates
         # keycount: don't need to calculate!! 
         overshoot = key_count - max_keys) %>%
  # rename motor variables - subject level covariates.
  rename(motor_skills_easy = median_RT_thumb, 
         motor_skills_hard = median_RT_ring,
         IQ = WASI_FSIQ)

# make trial 1-42 instead of 2 blocks of 21 
beh_comp_long3$Trial_Number_all <- ifelse(beh_comp_long3$Run_number == "RUN1", beh_comp_long3$Trial_Number, ifelse(beh_comp_long3$Run_number == "RUN2", beh_comp_long3$Trial_Number + 21, NA))
```


### create mean centered covariates
```{r}
beh_comp_long <- beh_comp_long3 %>%
  mutate (Reinforce_rate.c = Reinforce_rate - mean(Reinforce_rate, na.rm = T), 
          Reinforce_easy.c = Reinforce_easy - mean(Reinforce_easy, na.rm = T), 
          Reinforce_hard.c = Reinforce_hard - mean(Reinforce_hard, na.rm = T), 
          AGE.c = AGE - mean(AGE, na.rm = T), 
          SEX.c = SEX - mean(SEX, na.rm = T), 
          Trial_Number.c = Trial_Number - mean(Trial_Number, na.rm= T), 
          proportion_hard.c = proportion_hard - mean(proportion_hard), 
          IQ.c = IQ - mean(IQ, na.rm = T))
```

## make WSLS dataset (separate from regular)
add WSLS variables, shifted to prior trial
using the entire dataset, including misses...
NOTE: this excludes the first trial of each run because the prior trial is NA. 
```{r}
# make a copy of the dataset, remove all of the first trials, and mark them as 100 to keep out of place.
df_copy2 <- beh_comp_long %>%
  # making a copy that adds 1 to trial number
  mutate(Trial_Number = Trial_Number + 1) %>%
  # so effort choice prior for trial 2 represents the effort choice from trial 1 
  select(SUBJECTID, Run_number, Trial_Number, Effort_Choice, Feedback) %>%
  rename(Effort_Choice_prior = Effort_Choice, 
         Feedback_prior = Feedback) 

# now re-sort the data, so that all trials are shifted up 1 place. 
df_copy2 <- df_copy2[order(df_copy2$SUBJECTID, df_copy2$Run_number, df_copy2$Trial_Number),]

# now merge this new thing with orig data, by sub, run, and Trial_Number! 
beh_comp_long_WSLS <- merge(beh_comp_long, df_copy2, by = c("SUBJECTID", "Run_number", "Trial_Number"), all = T) %>%
  # exclude the first trial of each run because the prior trial is NA.
  filter(!is.na(Effort_Choice) & Trial_Number != 1) %>% 
## calculate stay-shift variables, 1 = stay, 0 = shift
  ## don't count missed choices for current or prior trial! 
  mutate(stay_shift = ifelse(Effort_Choice == "Miss" | Effort_Choice_prior == "Miss", NA, 
                             ifelse(Effort_Choice == Effort_Choice_prior, 1, 0)),
         # making a new variable that counts turtles as setbacks.
         Feedback_prior_inclturtle = as.factor(ifelse(Feedback_prior == "Too_slow", "Setback", as.character(Feedback_prior)))) %>%
  filter(Effort_Choice_prior != "Miss")
```

### sanity check for WSLS variables
```{r}
# NA = choices that were missed for current or prior trial - excluding both!! 
summary(as.factor(beh_comp_long_WSLS$stay_shift)) 

# missed choices are coded here, just making sure formatted correctly.
summary(as.factor(beh_comp_long_WSLS$Effort_Choice_prior)) 

# NA = choices that were missed, keeping too slow as a separate level.
summary(as.factor(beh_comp_long_WSLS$Feedback_prior)) 

# NA = choices that were missed, too slow feedback was counted as setback
summary(as.factor(beh_comp_long_WSLS$Feedback_prior_inclturtle)) 
```


## Make subject-level dataframe
```{r}
# make a subject-specific summary of their overall choices
beh_comp_subj <- beh_comp_long %>%
  group_by(SUBJECTID) %>%
  summarize(ft_version = ft_version[1],
            task_version = task_version.x[1],
            SEX = mean(SEX), 
            AGE = mean(AGE, na.rm = T),
            IQ = mean(IQ, na.rm = T),
            Fam_inc_needs = mean(INC_ITN_HOUSE, na.rm = T),
            N_trials = n(), 
            prop_hard_choices = mean(Effort_Choice.n, na.rm = T),
            Reinforce_rate  = mean(Reinforce_rate, na.rm = T), # MEAN
            Reinforce_hard = mean(Reinforce_hard, na.rm = T),
            Reinforce_easy = mean(Reinforce_easy, na.rm = T),
            perceived_reinforce  = mean(perceived_reinforce, na.rm = T), # post-test
            perceived_control  = mean(perceived_control, na.rm = T), # post-test
            hard_effort_perceived  = mean(hard_effort_perceived, na.rm = T), # post-test
            easy_effort_perceived  = mean(easy_effort_perceived, na.rm = T),# post-test
            # for each subject, taking the median of their median RT for each trial of finger presses... 
            # not ideal?
            motor_skills_easy  = median(motor_skills_easy, na.rm = T), # median RT from finger tapping thumb
            motor_skills_hard = median(motor_skills_hard, na.rm = T), # median RT from finger tapping ring
          #  max_keys_easy = mean(max_keys_easy, na.rm = T),# removing, because it's always 3! never changes.
            hard_task_titration = mean(hard_task_titration, na.rm = T),
          fun = mean(fun, na.rm = T),
          motivated = mean(motivated, na.rm = T), 
          sleepy = mean(sleepy, na.rm = T), 
          frustrated = mean(frustrated, na.rm = T), 
          win_feeling = mean(win_feeling, na.rm = T), 
          lose_feeling = mean(lose_feeling, na.rm = T)) %>%
  # add mean centered variables
  mutate(Reinforce_rate.c = Reinforce_rate - mean(Reinforce_rate, na.rm = T), 
          Reinforce_easy.c = Reinforce_easy - mean(Reinforce_easy, na.rm = T), 
          Reinforce_hard.c = Reinforce_hard - mean(Reinforce_hard, na.rm = T), 
          AGE.c = AGE - mean(AGE, na.rm = T), 
          SEX.c = SEX - mean(SEX, na.rm = T), 
          Trial_Number.c = N_trials - mean(N_trials, na.rm= T), 
          prop_hard_choices.c = prop_hard_choices - mean(prop_hard_choices), 
          IQ.c = IQ - mean(IQ, na.rm = T), 
          N_trials.c = N_trials- mean(N_trials, na.rm = T), 
          Fam_inc_needs.c = Fam_inc_needs- mean(Fam_inc_needs, na.rm = T)) # task titration

nrow(beh_comp_subj)
```

### checks: PA233 and PA253 are missing IQ -WASI not completed at visit! 
```{r}
# missing IQ 
NA_Check <- beh_comp_subj%>%
  filter(is.na(IQ)) 
NA_Check
```

## make subject-level data-frame for WSLS too 
```{r}

# make a subject-specific summary for WSLS - so grouped by feedback X effort! 
beh_comp_subj_WSLS <- beh_comp_long_WSLS %>%
  group_by(SUBJECTID, Feedback_prior, Effort_Choice_prior) %>%
  summarize(ft_version = ft_version[1],
            task_version = task_version.x[1],
            SEX = mean(SEX), 
            AGE = mean(AGE, na.rm = T),
            IQ = mean(IQ, na.rm = T),
             Fam_inc_needs = mean(INC_ITN_HOUSE, na.rm = T),
           N_trials = n(),
            stay_shift = mean(stay_shift, na.rm = T),
            prop_hard_choices = mean(Effort_Choice.n, na.rm = T),
            Reinforce_rate  = mean(Reinforce_rate, na.rm = T), # MEAN
            Reinforce_hard = mean(Reinforce_hard, na.rm = T),
            Reinforce_easy = mean(Reinforce_easy, na.rm = T),
            perceived_reinforce  = mean(perceived_reinforce, na.rm = T), # post-test
            perceived_control  = mean(perceived_control, na.rm = T), # post-test
            hard_effort_perceived  = mean(hard_effort_perceived, na.rm = T), # post-test
            easy_effort_perceived  = mean(easy_effort_perceived, na.rm = T),# post-test
            motor_skills_easy  = mean(motor_skills_easy, na.rm = T), # median RT from finger tapping thumb
            motor_skills_hard = mean(motor_skills_hard, na.rm = T), # median RT from finger tapping ring
          #  max_keys_easy = mean(max_keys_easy, na.rm = T),# removing, because it's always 3! never changes.
            hard_task_titration = mean(hard_task_titration, na.rm = T),
          fun = mean(fun, na.rm = T),
          motivated = mean(motivated, na.rm = T), 
          sleepy = mean(sleepy, na.rm = T), 
          frustrated = mean(frustrated, na.rm = T), 
          win_feeling = mean(win_feeling, na.rm = T), 
          lose_feeling = mean(lose_feeling, na.rm = T)) %>%
  # add mean centered variables
  mutate(Reinforce_rate.c = Reinforce_rate - mean(Reinforce_rate, na.rm = T), 
          Reinforce_easy.c = Reinforce_easy - mean(Reinforce_easy, na.rm = T), 
          Reinforce_hard.c = Reinforce_hard - mean(Reinforce_hard, na.rm = T), 
          AGE.c = AGE - mean(AGE, na.rm = T), 
          SEX.c = SEX - mean(SEX, na.rm = T), 
          Trial_Number.c = N_trials - mean(N_trials, na.rm= T), 
          prop_hard_choices.c = prop_hard_choices - mean(prop_hard_choices), 
          IQ.c = IQ - mean(IQ, na.rm = T), 
          N_trials.c = N_trials- mean(N_trials, na.rm = T), 
          Fam_inc_needs.c = Fam_inc_needs- mean(Fam_inc_needs, na.rm = T)) # task titration)  # task titration

```


### save this behavioral data 
```{r}
save(beh_comp_subj, file = "cleaned_data/COMPS_ONLY/beh_comp_subj.Rdata")
save(beh_comp_long, file = "cleaned_data/COMPS_ONLY/beh_comp_long.Rdata")

save(beh_comp_subj_WSLS, file = "cleaned_data/COMPS_ONLY/beh_comp_subj_WSLS.Rdata")
save(beh_comp_long_WSLS, file = "cleaned_data/COMPS_ONLY/beh_comp_long_WSLS.Rdata")

```


# Add ROI analysis brain data 
updated october 8, 2019 to include teh complete model with all possible copes...
needs to be updated to include PA255
```{r}
load(file = "cleaned_data/FSL_cope_files/complete_EV_copes.Rdata")
nrow(complete_EV_copes)
```

```{r}
# DEPRACATED FROM PRIOR LEVEL1 VERSIONS
## load betas from collapsed EV model (all subs)

#oad("cleaned_data/collapsed_EV_copes.Rdata")
#nrow(collapsed_EV_copes)


## load follow-up model betas (subset of subjects)
### choice contrast betas

#load("cleaned_data/choice_contrast_copes.Rdata")
#nrow(choice_contrast_copes)

### hard FB betas

#load("cleaned_data/hard_FB_contrast_copes.Rdata")
#nrow(hard_FB_contrast_copes)

```


### load data from progress report QC and merge with betas 
```{R}
load("cleaned_data/demo_and_QC/all_data_QC_and_demographics_wide2019-11-26.Rdata")

# only keep people in this usable list!! 
cope_df2 <- merge(complete_EV_copes, df_scan_usable, by = "SUBJECTID")
nrow(cope_df2)
# add in follow-up betas
#cope_df3 <- merge(cope_df2, choice_contrast_copes,by = "SUBJECTID", all = T)
#cope_df4 <- merge(cope_df3, hard_FB_contrast_copes, by = "SUBJECTID", all = T)
#nrow(cope_df4)
```

### add motion!
```{r}
load("../../FSL_pipeline/1.motion_assess/compiled_motion_info_2019-04-10.Rdata")
motion_df <- merged_df %>%
  group_by(SUBJECTID) %>%
  summarize(total_TRs_censored = sum(censored_TRs, na.rm = T), 
            meanFD_included_trs = mean(meanFD_included_trs, na.rm = T), 
            meanFD_all_trs = mean(meanFD_all_trs, na.rm = T))

cope_df3 <- merge(cope_df2, motion_df, by = "SUBJECTID")
nrow(cope_df3)
```


## combine behavior and scan data (wide & long)

###  BEH + SCAN WIDE DATA 
two versions: regular behavior and WSLS behavior
make sure only including comparisons here! comparisons includes DC, excludes PI or DA.

```{r}
beh_scan_comp_wide <- merge(beh_comp_subj, cope_df3, by = "SUBJECTID")
nrow(beh_scan_comp_wide)
save(beh_scan_comp_wide, file = "cleaned_data/COMPS_ONLY/beh_scan_comp_wide.Rdata")

beh_scan_comp_wide_WSLS <- merge(beh_comp_subj_WSLS, cope_df3, by = "SUBJECTID")
save(beh_scan_comp_wide_WSLS, file = "cleaned_data/COMPS_ONLY/beh_scan_comp_wide_WSLS.Rdata")

```


###  BEH + SCAN LONG DATA 
two versions: regular behavior and WSLS behavior
```{r}
beh_scan_comp_long <- merge(beh_comp_long, cope_df3, by = "SUBJECTID")
save(beh_scan_comp_long, file = "cleaned_data/COMPS_ONLY/beh_scan_comp_long.Rdata")
    
beh_scan_comp_long_WSLS <- merge(beh_comp_long_WSLS, cope_df3, by = "SUBJECTID")
save(beh_scan_comp_long_WSLS, file = "cleaned_data/COMPS_ONLY/beh_scan_comp_long_WSLS.Rdata")

```
